{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python387jvsc74a57bd01baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253",
   "display_name": "Python 3.8.7 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Melbourne House Prices - Kaggle Tutorial\n",
    "\n",
    "## Data Exploration\n",
    "The first step in any machine learning project is to familiarise with the data. Pandas will be used for this project. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "source": [
    "The most important part of the Pandas library is the [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). A DataFrame holds data in a similar fashion to a sheet in Excel, or a table in a SQL database.\n",
    "\n",
    "Firstly, the file path for the csv containing the data is saved in a variable for ease of access.\n",
    "\n",
    "Then, the csv is read using and the data is stored in a DataFrame title melbourne_data.\n",
    "\n",
    "The Melbourne data has some missing values (some houses for which some variables were not recorded). The simplest option that will be used on this dataset is to drop houses with missing values using the [pandas.dropna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_file_path = 'melb_data.csv'\n",
    "\n",
    "melbourne_data = pd.read_csv(melbourne_file_path)\n",
    "\n",
    "melbourne_data = melbourne_data.dropna(axis = 0)"
   ]
  },
  {
   "source": [
    "Overview of the \"cleaned up\" data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Rooms         Price     Distance     Postcode     Bedroom2  \\\n",
       "count  6196.000000  6.196000e+03  6196.000000  6196.000000  6196.000000   \n",
       "mean      2.931407  1.068828e+06     9.751097  3101.947708     2.902034   \n",
       "std       0.971079  6.751564e+05     5.612065    86.421604     0.970055   \n",
       "min       1.000000  1.310000e+05     0.000000  3000.000000     0.000000   \n",
       "25%       2.000000  6.200000e+05     5.900000  3044.000000     2.000000   \n",
       "50%       3.000000  8.800000e+05     9.000000  3081.000000     3.000000   \n",
       "75%       4.000000  1.325000e+06    12.400000  3147.000000     3.000000   \n",
       "max       8.000000  9.000000e+06    47.400000  3977.000000     9.000000   \n",
       "\n",
       "          Bathroom          Car      Landsize  BuildingArea    YearBuilt  \\\n",
       "count  6196.000000  6196.000000   6196.000000   6196.000000  6196.000000   \n",
       "mean      1.576340     1.573596    471.006940    141.568645  1964.081988   \n",
       "std       0.711362     0.929947    897.449881     90.834824    38.105673   \n",
       "min       1.000000     0.000000      0.000000      0.000000  1196.000000   \n",
       "25%       1.000000     1.000000    152.000000     91.000000  1940.000000   \n",
       "50%       1.000000     1.000000    373.000000    124.000000  1970.000000   \n",
       "75%       2.000000     2.000000    628.000000    170.000000  2000.000000   \n",
       "max       8.000000    10.000000  37000.000000   3112.000000  2018.000000   \n",
       "\n",
       "         Lattitude   Longtitude  Propertycount  \n",
       "count  6196.000000  6196.000000    6196.000000  \n",
       "mean    -37.807904   144.990201    7435.489509  \n",
       "std       0.075850     0.099165    4337.698917  \n",
       "min     -38.164920   144.542370     389.000000  \n",
       "25%     -37.855438   144.926198    4383.750000  \n",
       "50%     -37.802250   144.995800    6567.000000  \n",
       "75%     -37.758200   145.052700   10175.000000  \n",
       "max     -37.457090   145.526350   21650.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rooms</th>\n      <th>Price</th>\n      <th>Distance</th>\n      <th>Postcode</th>\n      <th>Bedroom2</th>\n      <th>Bathroom</th>\n      <th>Car</th>\n      <th>Landsize</th>\n      <th>BuildingArea</th>\n      <th>YearBuilt</th>\n      <th>Lattitude</th>\n      <th>Longtitude</th>\n      <th>Propertycount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6196.000000</td>\n      <td>6.196000e+03</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.931407</td>\n      <td>1.068828e+06</td>\n      <td>9.751097</td>\n      <td>3101.947708</td>\n      <td>2.902034</td>\n      <td>1.576340</td>\n      <td>1.573596</td>\n      <td>471.006940</td>\n      <td>141.568645</td>\n      <td>1964.081988</td>\n      <td>-37.807904</td>\n      <td>144.990201</td>\n      <td>7435.489509</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.971079</td>\n      <td>6.751564e+05</td>\n      <td>5.612065</td>\n      <td>86.421604</td>\n      <td>0.970055</td>\n      <td>0.711362</td>\n      <td>0.929947</td>\n      <td>897.449881</td>\n      <td>90.834824</td>\n      <td>38.105673</td>\n      <td>0.075850</td>\n      <td>0.099165</td>\n      <td>4337.698917</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.310000e+05</td>\n      <td>0.000000</td>\n      <td>3000.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1196.000000</td>\n      <td>-38.164920</td>\n      <td>144.542370</td>\n      <td>389.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>6.200000e+05</td>\n      <td>5.900000</td>\n      <td>3044.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>152.000000</td>\n      <td>91.000000</td>\n      <td>1940.000000</td>\n      <td>-37.855438</td>\n      <td>144.926198</td>\n      <td>4383.750000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>8.800000e+05</td>\n      <td>9.000000</td>\n      <td>3081.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>373.000000</td>\n      <td>124.000000</td>\n      <td>1970.000000</td>\n      <td>-37.802250</td>\n      <td>144.995800</td>\n      <td>6567.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.000000</td>\n      <td>1.325000e+06</td>\n      <td>12.400000</td>\n      <td>3147.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>628.000000</td>\n      <td>170.000000</td>\n      <td>2000.000000</td>\n      <td>-37.758200</td>\n      <td>145.052700</td>\n      <td>10175.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>8.000000</td>\n      <td>9.000000e+06</td>\n      <td>47.400000</td>\n      <td>3977.000000</td>\n      <td>9.000000</td>\n      <td>8.000000</td>\n      <td>10.000000</td>\n      <td>37000.000000</td>\n      <td>3112.000000</td>\n      <td>2018.000000</td>\n      <td>-37.457090</td>\n      <td>145.526350</td>\n      <td>21650.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "melbourne_data.describe()"
   ]
  },
  {
   "source": [
    "The dataset has too mane variables to be efficiently analysed. One way to cull the data is by intrinsic knowledge of what's required from the dataset. \n",
    "\n",
    "There are many ways to select a subset of the data, however two approaches will be used in this project: \n",
    "*   Dot notation: Dot notation is used to select the \"prediction target\"\n",
    "*   Selecting with a column list, used to select the \"features\"\n",
    "\n",
    "The columns of the dataset are interrogated to establish the prediction targget and features."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n",
       "       'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "source": [
    "melbourne_data.columns"
   ]
  },
  {
   "source": [
    "## Selecting The Prediction Target\n",
    "A variable can be pulled out with dot-notation. This single column is stored in a Series, which is broadly like a DataFrame with only a single column of data.\n",
    "\n",
    "The dot notation is used to select the column that is required to be predicted, which is called the prediction target. By convention, the prediction target is called **y**."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = melbourne_data.Price"
   ]
  },
  {
   "source": [
    "## Choosing Features\n",
    "The columns that are inputted into the model (and later used to make predictions) are called \"features.\" In this case, those would be the columns used to determine the home price. Sometimes, all columns will be used except the target as features. Other times it ismore value added to use fewer features.\n",
    "\n",
    "By convention, this data is called X.\n",
    "\n",
    "For now, a model will be built with only a few features. Later on it'll be iterated and compared to models built with different features."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"['FullBath', '2ndFlrSF', 'LotArea', 'BedroomAbvGr', '1stFlrSF', 'TotRmsAbvGrd'] not in index\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-39c1203d29b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'LotArea'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'YearBuilt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'1stFlrSF'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2ndFlrSF'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'FullBath'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BedroomAbvGr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TotRmsAbvGrd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmelbourne_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1263\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1313\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['FullBath', '2ndFlrSF', 'LotArea', 'BedroomAbvGr', '1stFlrSF', 'TotRmsAbvGrd'] not in index\""
     ]
    }
   ],
   "source": [
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\n",
    "test_features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "\n",
    "X = melbourne_data[melbourne_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Rooms     Bathroom      Landsize    Lattitude   Longtitude\n",
       "count  6196.000000  6196.000000   6196.000000  6196.000000  6196.000000\n",
       "mean      2.931407     1.576340    471.006940   -37.807904   144.990201\n",
       "std       0.971079     0.711362    897.449881     0.075850     0.099165\n",
       "min       1.000000     1.000000      0.000000   -38.164920   144.542370\n",
       "25%       2.000000     1.000000    152.000000   -37.855438   144.926198\n",
       "50%       3.000000     1.000000    373.000000   -37.802250   144.995800\n",
       "75%       4.000000     2.000000    628.000000   -37.758200   145.052700\n",
       "max       8.000000     8.000000  37000.000000   -37.457090   145.526350"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rooms</th>\n      <th>Bathroom</th>\n      <th>Landsize</th>\n      <th>Lattitude</th>\n      <th>Longtitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n      <td>6196.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.931407</td>\n      <td>1.576340</td>\n      <td>471.006940</td>\n      <td>-37.807904</td>\n      <td>144.990201</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.971079</td>\n      <td>0.711362</td>\n      <td>897.449881</td>\n      <td>0.075850</td>\n      <td>0.099165</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>-38.164920</td>\n      <td>144.542370</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>152.000000</td>\n      <td>-37.855438</td>\n      <td>144.926198</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>373.000000</td>\n      <td>-37.802250</td>\n      <td>144.995800</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.000000</td>\n      <td>2.000000</td>\n      <td>628.000000</td>\n      <td>-37.758200</td>\n      <td>145.052700</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>37000.000000</td>\n      <td>-37.457090</td>\n      <td>145.526350</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
       "1      2       1.0     156.0   -37.8079    144.9934\n",
       "2      3       2.0     134.0   -37.8093    144.9944\n",
       "4      4       1.0     120.0   -37.8072    144.9941\n",
       "6      3       2.0     245.0   -37.8024    144.9993\n",
       "7      2       1.0     256.0   -37.8060    144.9954"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rooms</th>\n      <th>Bathroom</th>\n      <th>Landsize</th>\n      <th>Lattitude</th>\n      <th>Longtitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>156.0</td>\n      <td>-37.8079</td>\n      <td>144.9934</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2.0</td>\n      <td>134.0</td>\n      <td>-37.8093</td>\n      <td>144.9944</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>120.0</td>\n      <td>-37.8072</td>\n      <td>144.9941</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3</td>\n      <td>2.0</td>\n      <td>245.0</td>\n      <td>-37.8024</td>\n      <td>144.9993</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>256.0</td>\n      <td>-37.8060</td>\n      <td>144.9954</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "source": [
    "## Building the Model\n",
    "The scikit-learn library is used to create the model. When coding, this library is written as sklearn, as seen in the sample code. Scikit-learn is easily the most popular library for modeling the types of data typically stored in DataFrames.\n",
    "\n",
    "The steps to building and using a model are:\n",
    "\n",
    "*   Define: What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.\n",
    "*   Fit: Capture patterns from provided data. This is the heart of modeling.\n",
    "*   Predict: Just what it sounds like\n",
    "*   Evaluate: Determine how accurate the model's predictions are.\n",
    "\n",
    "Many machine learning models allow some randomness in model training. Specifying a number for random_state ensures the same results are returned in each run. This is considered a good practice. Any number can be used and model quality won't depend meaningfully on exactly what value was chosen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "melbourne_model = DecisionTreeRegressor(random_state = 1)\n",
    "\n",
    "melbourne_model.fit(X, y)"
   ]
  },
  {
   "source": [
    "## Model Predictions\n",
    "The model is now fitted and can be used to make predictions.\n",
    "\n",
    "In practice, predictions would be for new houses coming on the market rather than the houses for which prices already exist for in the dataset. However, predictions will be made for the first few rows of the training data to see how the predict function works."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Making predictions for the following 5 houses\n   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n1      2       1.0     156.0   -37.8079    144.9934\n2      3       2.0     134.0   -37.8093    144.9944\n4      4       1.0     120.0   -37.8072    144.9941\n6      3       2.0     245.0   -37.8024    144.9993\n7      2       1.0     256.0   -37.8060    144.9954\nThe predictions are:\n[1035000. 1465000. 1600000. 1876000. 1636000.]\nThe data for these houses for comparison to what the model predicted:\n       Suburb          Address  Rooms Type      Price Method SellerG  \\\n1  Abbotsford  25 Bloomburg St      2    h  1035000.0      S  Biggin   \n2  Abbotsford     5 Charles St      3    h  1465000.0     SP  Biggin   \n4  Abbotsford      55a Park St      4    h  1600000.0     VB  Nelson   \n6  Abbotsford     124 Yarra St      3    h  1876000.0      S  Nelson   \n7  Abbotsford    98 Charles St      2    h  1636000.0      S  Nelson   \n\n        Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n1  4/02/2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n2  4/03/2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n4  4/06/2016       2.5    3067.0  ...       1.0  2.0     120.0         142.0   \n6  7/05/2016       2.5    3067.0  ...       2.0  0.0     245.0         210.0   \n7  8/10/2016       2.5    3067.0  ...       1.0  2.0     256.0         107.0   \n\n   YearBuilt  CouncilArea Lattitude  Longtitude             Regionname  \\\n1     1900.0        Yarra  -37.8079    144.9934  Northern Metropolitan   \n2     1900.0        Yarra  -37.8093    144.9944  Northern Metropolitan   \n4     2014.0        Yarra  -37.8072    144.9941  Northern Metropolitan   \n6     1910.0        Yarra  -37.8024    144.9993  Northern Metropolitan   \n7     1890.0        Yarra  -37.8060    144.9954  Northern Metropolitan   \n\n  Propertycount  \n1        4019.0  \n2        4019.0  \n4        4019.0  \n6        4019.0  \n7        4019.0  \n\n[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print('Making predictions for the following 5 houses')\n",
    "print(X.head())\n",
    "print('The predictions are:')\n",
    "print(melbourne_model.predict(X.head()))\n",
    "print('The data for these houses for comparison to what the model predicted:')\n",
    "print(melbourne_data.head())"
   ]
  },
  {
   "source": [
    "## Model Validation\n",
    "In most (though not all) applications, the relevant measure of model quality is **predictive accuracy**.\n",
    "\n",
    "There are many metrics for summarising model quality, a common one being **Mean Absolute Error** (or **MAE**). The formula for the MAE metric is: *error = actual - predicted*\n",
    "\n",
    "The MAE metric takes the absolute value of each error, thus converting each error to a positive number. It then takes the average of those absolute errors and this is the measure of model quality. In other words, this translates to \"On average, the predictions are off by about X\".\n",
    "\n",
    "The mean absolute error metric can be imported as *from sklearn.metrics import mean_absolute_error*."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1115.7467183128902"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "source": [
    "A common mistake on assessing predictive accuracy is making predictions with the training data and comparing those predictions to the target values in the training data. This measure is called an \"in-sample\" score. The problem with using in-sample scores is that the model is trained is learning patterns found in the training set, Thus, testing on the training set has the risk of evaluating the incorrect predictive accuracy as the model may have picked up a pattern on a given dataset taht may not actually be important for the prediction in question.\n",
    "\n",
    "Consequently, since models' practical value comes from making predictions on new data, performance needs to be measured on data that wasn't used to build the model. The most straightforward way to do this is to exclude a portion of the data from the model-building process, and tehn use those to test the model's accuracy on data it hasn't seen before. This data is called **validation data**.\n",
    "\n",
    "The scikit-learn library has a function *train_test_split* to break up the data into two pieces, thus two datasets where one can be used for training and the other can be used for validation. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "274541.772326232"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "val_predictions = melbourne_model.predict(val_X)\n",
    "mean_absolute_error(val_y, val_predictions)"
   ]
  },
  {
   "source": [
    "## Model Validation Methods Comparison\n",
    "Comparing the two model validation results, the in-sample validation and validation based on split data, it can be seen that the error for the latter dramatically increased ($1115 to $275,680) thus demonstrating the risks of validating a model with in-sample data.\n",
    "\n",
    "There are many ways to improve an underperforming model, such as experimenting with different features that could be more appropriate for the dataset in question or different model types."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Model Optimisation\n",
    "\n",
    "Having a reliable way to measure model accuracy allows to experiment with different models and establish which one better predicts what is required based on a given dataset. But what alternatives are there for models?\n",
    "\n",
    "The scikit-learn's [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) has many options for decision tree model used in this project.\n",
    "\n",
    "In practice, it's not uncommon for a tree to have 10 splits between the top level (all houses) and a leaf. As the tree gets deeper, the dataset gets sliced up into leaves with fewer houses. If a tree only had 1 split, it divides the data into 2 groups. If each group is split again, it would return 4 groups of houses. Splitting each of those again would create 8 groups. If the number of groups keeps doubling by adding more splits at each level, it'd return 210  groups of houses by the time it'd get to the 10th level. That's 1024 leaves.\n",
    "\n",
    "When the houses are divided amongst many leaves, fewer houses are found in each leaf. Leaves with very few houses will make predictions that are quite close to those homes' actual values, but they may make very unreliable predictions for new data (because each prediction is based on only a few houses).\n",
    "\n",
    "There are a few alternatives for controlling the tree depth, and many allow for some routes through the tree to have greater depth than other routes. But the max_leaf_nodes argument provides a very sensible way to control overfitting vs underfitting.\n",
    "\n",
    "Furthermore, a utility function can be used to help compare MAE scores from different values for max_leaf_nodes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "source": [
    "A for-loop can be used to compare the accuracy of models built with different values for max_leaf_nodes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  385696\nMax leaf nodes: 50  \t\t Mean Absolute Error:  279794\nMax leaf nodes: 500  \t\t Mean Absolute Error:  261718\nMax leaf nodes: 5000  \t\t Mean Absolute Error:  271996\n"
     ]
    }
   ],
   "source": [
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "source": [
    "## Fit the Optimised Model\n",
    "With the model now optimised, based on the optimal number of leaf nodes for this dataset, it can be builkt with the whole dataset to utilise the full volume of data to maximise accuracy. Part of the data is no longer required for validation as all the modelling decisions have been made."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=500, random_state=0)"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "final_model = DecisionTreeRegressor(max_leaf_nodes = 500, random_state = 0)\n",
    "\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "source": [
    "## Random Forests Algorithm\n",
    "Decision trees create a dilemma.  A deep tree with lots of leaves will overfit because each prediction is coming from historical data from only the few houses at its leaf. But a shallow tree with few leaves will underfit and perform poorly because it fails to capture as many distinctions in the raw data. \n",
    "\n",
    "Even today's most sophisticated modelling techniques face this tension between overfitting and underfitting. However, many models have clever ideas that can lead to better performance.\n",
    "\n",
    "The **random forest** modelling technique uses many trees and it makes a prediction by averaging the predictions of each component tree. In general, it has much better predictive accuracy than a single decision tree and it works well with default parameters (unlike more complex models that are sensitive to their hyperparameters and require tuning). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean Absolute Error is: 207190\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state = 1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "\n",
    "forest_mae = mean_absolute_error(val_y, melb_preds)\n",
    "\n",
    "print('Mean Absolute Error is: %d' %(forest_mae))"
   ]
  },
  {
   "source": [
    "There is likely room for improvement, however even with default parameters the random forest algorithm delivered a significant improvement over the best/tuned decision tree model.\n",
    "\n",
    "Now that the mean absolute error for the random forest algorithm has been established, the model can be trained on the full dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "rf_model_full_dataset = RandomForestRegressor(random_state = 1)\n",
    "\n",
    "rf_model_full_dataset.fit(X, y)"
   ]
  },
  {
   "source": [
    "## Predictions on New Data\n",
    "The 'test.csv' file has a set of new data that can be used to make predictions with trained model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = 'test.csv'\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "source": [
    "With the data imported, the prediction dataset with only the required features can be created."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_data[test_features]"
   ]
  },
  {
   "source": [
    "Finally, the model can be used to make predictions based on the test data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "X has 7 features, but DecisionTreeRegressor is expecting 5 features as input.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-f65dc763da1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model_full_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[1;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0m\u001b[0;32m    403\u001b[0m                                     reset=False)\n\u001b[0;32m    404\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    366\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[1;31mValueError\u001b[0m: X has 7 features, but DecisionTreeRegressor is expecting 5 features as input."
     ]
    }
   ],
   "source": [
    "test_predictions = rf_model_full_dataset.predict(test_X)"
   ]
  },
  {
   "source": [
    "## Kaggle Competitions\n",
    "The code below demonstrates how predictions can be saved in the format used for competition scoring and thus be correctly submitted.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_preds' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-a62d13c619c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submission.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_preds' is not defined"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame({'Id': test_data.Id, 'SalePrice': test_predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ]
}